{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a360d942",
   "metadata": {},
   "source": [
    "# Testing Notebook\n",
    "The purpose of this notebook is to verify that all the components of the larger program are functioning properly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c47c6f34",
   "metadata": {},
   "source": [
    "# Setup\n",
    "This section checks to see if all the libraries import correctly and that we can access the GPUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e47ec698",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imports successful!\n",
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from agents.dqn_agent import QNetwork, DQNAgent\n",
    "from common.replay_buffer import ReplayBuffer, Experience\n",
    "\n",
    "print(\"Imports successful!\")\n",
    "\n",
    "# Define configuration parameters for testing\n",
    "# These would normally come from a .yaml file\n",
    "\n",
    "# Environment/Wrapper params\n",
    "INPUT_SHAPE = (4, 84, 84) # (num_stack, height, width)\n",
    "NUM_ACTIONS = 9          # Ms. Pac-Man has 9 actions\n",
    "\n",
    "# Replay Buffer params\n",
    "BUFFER_CAPACITY = 1000\n",
    "BATCH_SIZE = 4           # Use a small batch size for easy testing\n",
    "\n",
    "# Set the device for PyTorch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f518f93",
   "metadata": {},
   "source": [
    "# Testing QNetwork\n",
    "The following checks to make sure that we can successfully create an instance of a QNetwork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e2410753",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Testing QNetwork ---\n",
      "Successfully instantiated QNetwork.\n",
      "QNetwork(\n",
      "  (conv): Sequential(\n",
      "    (0): Conv2d(4, 32, kernel_size=(8, 8), stride=(4, 4))\n",
      "    (1): ReLU()\n",
      "    (2): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2))\n",
      "    (3): ReLU()\n",
      "    (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (5): ReLU()\n",
      "  )\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=3136, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "\n",
      "Created a dummy numpy input with shape: (4, 4, 84, 84) and dtype: uint8\n",
      "Converted to a dummy torch tensor with shape: torch.Size([4, 4, 84, 84]) and dtype: torch.float32\n",
      "\n",
      "Performed forward pass successfully.\n",
      "Output tensor shape: torch.Size([4, 9])\n",
      "Expected output shape: (4, 9)\n",
      "\n",
      "Test PASSED: Output shape is correct.\n"
     ]
    }
   ],
   "source": [
    "print(\"--- Testing QNetwork ---\")\n",
    "\n",
    "# Instantiate the network\n",
    "q_network = QNetwork(input_shape=INPUT_SHAPE, num_actions=NUM_ACTIONS).to(device)\n",
    "print(\"Successfully instantiated QNetwork.\")\n",
    "print(q_network) # Print the network architecture\n",
    "\n",
    "# Create a dummy input batch\n",
    "dummy_input_shape = (BATCH_SIZE,) + INPUT_SHAPE \n",
    "# Create a numpy array of random data with this shape\n",
    "dummy_np_array = np.random.rand(*dummy_input_shape).astype(np.uint8)\n",
    "\n",
    "print(f\"\\nCreated a dummy numpy input with shape: {dummy_np_array.shape} and dtype: {dummy_np_array.dtype}\")\n",
    "\n",
    "# Prepare the data for the network\n",
    "dummy_tensor = torch.tensor(dummy_np_array, dtype=torch.float32).to(device) / 255.0\n",
    "\n",
    "print(f\"Converted to a dummy torch tensor with shape: {dummy_tensor.shape} and dtype: {dummy_tensor.dtype}\")\n",
    "\n",
    "# Perform a forward pass\n",
    "with torch.no_grad(): # Disable gradient calculations because we are not training\n",
    "    output = q_network(dummy_tensor)\n",
    "\n",
    "print(f\"\\nPerformed forward pass successfully.\")\n",
    "print(f\"Output tensor shape: {output.shape}\")\n",
    "print(f\"Expected output shape: {(BATCH_SIZE, NUM_ACTIONS)}\")\n",
    "\n",
    "# Final check\n",
    "if output.shape == (BATCH_SIZE, NUM_ACTIONS):\n",
    "    print(\"\\nTest PASSED: Output shape is correct.\")\n",
    "else:\n",
    "    print(f\"\\nTest FAILED: Output shape is {output.shape}, but expected {(BATCH_SIZE, NUM_ACTIONS)}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d0ba868",
   "metadata": {},
   "source": [
    "# Test replay_buffer.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2dc261d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Testing Replay Buffer ---\n",
      "Successfully instantiated ReplayBuffer with capacity: 1000 and batch size: 4\n",
      "\n",
      "Adding 10 dummy experiences to the replay buffer...\n",
      "Current buffer size: 10 (should be 10)\n",
      "TEST PASSED: Replay buffer size is correct.\n",
      "\n",
      "Sampling a batch of size 4 from the replay buffer...\n",
      "Sampled states shape: (4, 4, 84, 84), Expected: (4, (4, 84, 84))\n",
      "Sampled actions shape: (4,), Expected: (4,)\n",
      "Sampled rewards shape: (4,), Expected: (4,)\n",
      "Sampled next_states shape: (4, 4, 84, 84), Expected: (4, (4, 84, 84))\n",
      "Sampled dones shape: (4,), Expected: (4,)\n",
      "TEST PASSED: Sampled batch shapes are correct.\n"
     ]
    }
   ],
   "source": [
    "print('\\n--- Testing Replay Buffer ---')\n",
    "\n",
    "# Instantiate the replay buffer\n",
    "replay_buffer = ReplayBuffer(capacity=BUFFER_CAPACITY, batch_size=BATCH_SIZE)\n",
    "print(f\"Successfully instantiated ReplayBuffer with capacity: {BUFFER_CAPACITY} and batch size: {BATCH_SIZE}\")\n",
    "\n",
    "# Create dummy experiences and add them to the buffer\n",
    "\n",
    "num_experiences_to_add = 10\n",
    "print(f\"\\nAdding {num_experiences_to_add} dummy experiences to the replay buffer...\")\n",
    "\n",
    "for i in range(num_experiences_to_add):\n",
    "    dummy_state = np.ones(INPUT_SHAPE) * i\n",
    "    dummy_action = i % NUM_ACTIONS\n",
    "    dummy_reward = float(i)\n",
    "    dummy_next_state = np.ones(INPUT_SHAPE) * (i + 1)\n",
    "    dummy_done = (i == num_experiences_to_add - 1) # Last experience is terminal\n",
    "\n",
    "    replay_buffer.add(dummy_state, dummy_action, dummy_reward, dummy_next_state, dummy_done)\n",
    "\n",
    "# Check length of buffer\n",
    "print(f\"Current buffer size: {len(replay_buffer)} (should be {num_experiences_to_add})\")\n",
    "if len(replay_buffer) == num_experiences_to_add:\n",
    "    print(\"TEST PASSED: Replay buffer size is correct.\")\n",
    "else:\n",
    "    print(\"TEST FAILED: Replay buffer size is incorrect.\")\n",
    "\n",
    "# Sample a batch\n",
    "print(f\"\\nSampling a batch of size {BATCH_SIZE} from the replay buffer...\")\n",
    "states, actions, rewards, next_states, dones = replay_buffer.sample()\n",
    "\n",
    "print(f\"Sampled states shape: {states.shape}, Expected: ({BATCH_SIZE}, {INPUT_SHAPE})\")\n",
    "print(f\"Sampled actions shape: {actions.shape}, Expected: ({BATCH_SIZE},)\")\n",
    "print(f\"Sampled rewards shape: {rewards.shape}, Expected: ({BATCH_SIZE},)\")\n",
    "print(f\"Sampled next_states shape: {next_states.shape}, Expected: ({BATCH_SIZE}, {INPUT_SHAPE})\")\n",
    "print(f\"Sampled dones shape: {dones.shape}, Expected: ({BATCH_SIZE},)\")\n",
    "\n",
    "# Final check for sampled batch shapes\n",
    "correct_shapes = all([\n",
    "    states.shape == (BATCH_SIZE, *INPUT_SHAPE),\n",
    "    actions.shape == (BATCH_SIZE,),\n",
    "    rewards.shape == (BATCH_SIZE,),\n",
    "    next_states.shape == (BATCH_SIZE, *INPUT_SHAPE),\n",
    "    dones.shape == (BATCH_SIZE,)\n",
    "])\n",
    "\n",
    "if correct_shapes:\n",
    "    print(\"TEST PASSED: Sampled batch shapes are correct.\")\n",
    "else:\n",
    "    print(\"TEST FAILED: Sampled batch shapes are incorrect.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "619d1f38",
   "metadata": {},
   "source": [
    "# Testing DQN Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2024f9e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Testing DQNAgent ---\n",
      "Successfully instantiated DQNAgent.\n",
      "\n",
      "--- Testing act() method ---\n",
      "Action taken with epsilon=1.0 (explore): 6\n",
      "Action taken with epsilon=0.0 (exploit): 2\n",
      "✅ Test PASSED: act() method returns an integer action.\n",
      "\n",
      "--- Testing learn() method ---\n",
      "Populating replay buffer with 4 experiences...\n",
      "Successfully called learn() method. Loss: 0.5260008573532104\n",
      "✅ Test PASSED: learn() method ran without errors and returned a float.\n",
      "\n",
      "--- Testing target network update ---\n",
      "✅ Test PASSED: Target network weights match policy network weights after update.\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Testing DQNAgent ---\")\n",
    "\n",
    "# 1. Instantiate the agent\n",
    "# We'll use the config parameters from Cell 1\n",
    "agent = DQNAgent(\n",
    "    input_shape=INPUT_SHAPE,\n",
    "    num_actions=NUM_ACTIONS,\n",
    "    replay_buffer_capacity=BUFFER_CAPACITY,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    learning_rate=0.001, # A dummy learning rate\n",
    "    gamma=0.99,\n",
    "    device=device\n",
    ")\n",
    "print(\"Successfully instantiated DQNAgent.\")\n",
    "\n",
    "# 2. Test the `act` method\n",
    "print(\"\\n--- Testing act() method ---\")\n",
    "# Create a dummy state\n",
    "dummy_state = np.random.rand(*INPUT_SHAPE)\n",
    "# Test with high epsilon (should be random)\n",
    "action_explore = agent.act(dummy_state, epsilon=1.0)\n",
    "print(f\"Action taken with epsilon=1.0 (explore): {action_explore}\")\n",
    "# Test with zero epsilon (should be exploit)\n",
    "action_exploit = agent.act(dummy_state, epsilon=0.0)\n",
    "print(f\"Action taken with epsilon=0.0 (exploit): {action_exploit}\")\n",
    "\n",
    "if isinstance(action_explore, int) and isinstance(action_exploit, int):\n",
    "    print(\"Test PASSED: act() method returns an integer action.\")\n",
    "else:\n",
    "    print(\"Test FAILED: act() method did not return an integer.\")\n",
    "\n",
    "\n",
    "# 3. Test the `learn` method\n",
    "print(\"\\n--- Testing learn() method ---\")\n",
    "# First, populate the buffer with enough experiences to form a batch\n",
    "print(f\"Populating replay buffer with {BATCH_SIZE} experiences...\")\n",
    "for _ in range(BATCH_SIZE):\n",
    "    dummy_experience = (\n",
    "        np.random.rand(*INPUT_SHAPE), \n",
    "        np.random.randint(NUM_ACTIONS), \n",
    "        np.random.rand(), \n",
    "        np.random.rand(*INPUT_SHAPE), \n",
    "        False\n",
    "    )\n",
    "    agent.replay_buffer.add(*dummy_experience)\n",
    "\n",
    "# Now, call the learn method\n",
    "try:\n",
    "    loss = agent.learn()\n",
    "    print(f\"Successfully called learn() method. Loss: {loss}\")\n",
    "    if isinstance(loss, float):\n",
    "        print(\"Test PASSED: learn() method ran without errors and returned a float.\")\n",
    "    else:\n",
    "        print(\"Test FAILED: learn() method did not return a float.\")\n",
    "except Exception as e:\n",
    "    print(f\"Test FAILED: learn() method raised an exception: {e}\")\n",
    "\n",
    "\n",
    "# 4. Test the target network update\n",
    "print(\"\\n--- Testing target network update ---\")\n",
    "try:\n",
    "    agent.update_target_network()\n",
    "    # Check if weights are indeed the same (optional, but good)\n",
    "    policy_dict = agent.q_policy_net.state_dict()\n",
    "    target_dict = agent.q_target_net.state_dict()\n",
    "    is_same = all(torch.equal(policy_dict[key], target_dict[key]) for key in policy_dict)\n",
    "    \n",
    "    if is_same:\n",
    "        print(\"Test PASSED: Target network weights match policy network weights after update.\")\n",
    "    else:\n",
    "        print(\"Test FAILED: Target network weights do not match.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Test FAILED: update_target_network() raised an exception: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da2cd969",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mspacman_rl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
